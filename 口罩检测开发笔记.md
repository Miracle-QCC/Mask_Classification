# 整体流程
1. 先准备口罩人脸数据训练一个轻量级分类模型，保存好模型，然后走一遍量化流程获得cvimodel（目前设定人脸大小固定为112*112）;
2. 然后将模型部署之face_capture.cpp中，设定在capture_face之后，只有capture=true的人脸进行预测;


## 1.模型获取
- 选定模型为MobileNetv3(https://github.com/xiaolai-sqlai/mobilenetv3/blob/adc0ca87e1dd8136cd000ae81869934060171689/mobilenetv3.py#L75),它是SOTA级别的轻量级模型;我将out = F.avg_pool2d(out, 7)修改为out = F.avg_pool2d(out, 3)，可以是的输入图片尺寸为112x112,同时降低Flops(原模型的Flops=0.07G，Params=1.23M)

修改之后，输入1x3x112x112的图片测试模型的Flops和Params
```
from thop import profile
net = MobileNetV3_Small()
torch.save(net.state_dict(),"x.pth")
x = torch.randn(1, 3, 112,112)
flops, params = profile(net, (x,))
print('flops: ', flops, 'params: ', params)
print('flops: %.2f G, params: %.2f M' % (flops / 1000000000.0, params / 1000000.0))
```
flops:  18249744.0 params:  1230029.0
flops: 0.02 G, params: 1.23 M，Flops不到原来的30%

- 数据准备:数据集使用北京服务器原来的数据,位于10.14.65.12:/dataset/face_mask_classification.tar.gz ，

|    | 训练集   | 测试集   |
|----|-------|-------|
| 戴口罩 | 21326 | 4329  |
| 不戴口罩 | 32141 | 7800  |
| 总数 | 53467 | 12129 |


- 训练120个epoch，batch_size=64
- 使用Adam作为优化器，lr=1e-4,L2正则化系数为1e-6，
- loss采用Focal loss(alpha=0.34),
- 对图片采用三种增强方法
```
transforms.RandomHorizontalFlip(),
transforms.RandomVerticalFlip(),
transforms.RandomRotation(30),
```

- 测试模型
```
python mobile_val.py

100%|██████████| 24/24 [00:46<00:00,  1.94s/it]
AP Score: 0.9811470142681705
```
## 2.量化
### 2.1 获取onnx

```python
import torch
from model import MobileNetV3_Small

model = MobileNetV3_Small()
ckpt = torch.load('lastest.pth')
model.load_state_dict(ckpt)
model.eval()

input_names = ['input']
output_names = ['output']

x = torch.randn(1, 3, 112, 112, requires_grad=True)

torch.onnx.export(model, x, 'Mobilenetv3_Small_112x112.onnx', input_names=input_names, output_names=output_names, verbose='True')
```

### 2.2 生成单精度mlir
```
model_transform.py --model_type onnx --model_name MobileNet \
--model_def Mobilenetv3_Small_112x112.onnx \
--image /work/test_00000044-face1.png \
--image_resize_dims 112,112 \
--keep_aspect_ratio true \
--net_input_dims 112,112 \
--raw_scale 1.0 \
--mean 0.5,0.5,0.5 \
--std 0.5,0.5,0.5 \
--input_scale 1.0 \
--pixel_format RGB_PLANAR \
--model_channel_order "rgb" \
--tolerance 0.99,0.99,0.99 \
--mlir Mobilenetv3_Small_112x112.mlir
```

### 2.3 生成calibration_table,混精度的
```
run_calibration.py Mobilenetv3_Small_112x112.mlir --dataset=/work/calibration --input_num=100 -o Mobilenetv3_Small_calibration_table

run_mix_precision.py \
Mobilenetv3_Small_112x112.mlir \
--dataset=/work/calibration \
--input_num=100 \
--calibration_table Mobilenetv3_Small_calibration_table \
--max_bf16_layers=5 \
-o Mobilenetv3_mix_precision_calibration_table
```

### 2.4 获得cvimodel（转换失败）
```
model_deploy.py --model_name MobileNet \
--mlir Mobilenetv3_Small_112x112.mlir \
--calibration_table Mobilenetv3_Small_calibration_table \
--quantize INT8 \
--chip cv182x \
--image /work/test_00000044-face1.png \
--tolerance 0.9,0.9,0.7 \
--correctness 0.99,0.99,0.99 \
--cvimodel Mobilenetv3_mix_precision.cvimodel
```


# **由于转换MobileNetv3失败，所以更换了另一个同等级的轻量级模型Ghostnet**
## 1.GhostNet模型获取
从https://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/ghostnet_pytorch获取代码，设定输入为112*112
```python
from thop import profile

net = ghostnet(num_classes=1)
x = torch.randn(1, 3, 112, 112)
flops, params = profile(net, (x,))
print('flops: ', flops, 'params: ', params)
print('flops: %.2f G, params: %.2f M' % (flops / 1000000000.0, params / 1000000.0))
```
flops: 0.04 G, params: 3.90 M

- 数据准备:数据集使用北京服务器原来的数据,位于10.14.65.12:/dataset/face_mask_classification.tar.gz ，

|    | 训练集   | 测试集   |
|----|-------|-------|
| 戴口罩 | 21326 | 4329  |
| 不戴口罩 | 32141 | 7800  |
| 总数 | 53467 | 12129 |


- 训练120个epoch，batch_size=64
- 使用Adam作为优化器，lr=1e-4,L2正则化系数为1e-6，
- loss采用Focal loss(alpha=0.34),
- 对图片采用三种增强方法
```
transforms.RandomHorizontalFlip(),
transforms.RandomVerticalFlip(),
transforms.RandomRotation(30),
```
- 测试模型
```
python ghost_val.py
100%|██████████| 24/24 [00:14<00:00,  1.71it/s]
AP Score: 0.986129186022517
```

## 2.ghost网络量化

### 2.1 获取onnx
```python
import torch
from GhostNet import ghostnet
model = ghostnet( num_classes=1)
ckpt = torch.load('ghostnet_last.pth')
model.load_state_dict(ckpt)
model.eval()

input_names = ['input']
output_names = ['output']

x = torch.randn(1, 3, 112, 112, requires_grad=True)

torch.onnx.export(model, x, 'ghostnet_112x112.onnx', input_names=input_names, output_names=output_names, verbose='True')
```

### 2.2 生成单精度mlir
```commandline
model_transform.py --model_type onnx --model_name ghostnet \
--model_def ghostnet_112x112.onnx \
--image /work/test_00000044-face1.png \
--image_resize_dims 112,112 \
--keep_aspect_ratio true \
--net_input_dims 112,112 \
--raw_scale 1.0 \
--mean 0.5,0.5,0.5 \
--std 0.5,0.5,0.5 \
--input_scale 1.0 \
--pixel_format RGB_PLANAR \
--model_channel_order "rgb" \
--tolerance 0.99,0.99,0.99 \
--mlir ghostnet_112x112.mlir
```

### 2.3 获取calibration_table
```commandline
run_calibration.py ghostnet_112x112.mlir --dataset=/work/calibration --input_num=100 -o ghostnet_112x112.mlir_calibration_table
```

### 2.4 生成cvimodel
```commandline
model_deploy.py --model_name ghostnet \
--mlir ghostnet_112x112.mlir \
--calibration_table ghostnet_112x112.mlir_calibration_table \
--quantize INT8 \
--chip cv182x \
--image /work/test_00000044-face1.png \
--tolerance 0.9,0.9,0.69 \
--correctness 0.99,0.99,0.99 \
--cvimodel ghostnet_112x112.cvimodel
```

### 2.5 测试cvimodel
- 统计ION内存
```
cvimodel_tool -a dump -i ghostnet_112x112.cvimodel
```
CviModel Need ION Memory Size: (4.20 MB)
